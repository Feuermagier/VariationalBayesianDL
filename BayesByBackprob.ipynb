{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://github.com/nitarshan/bayes-by-backprop/blob/master/Weight%20Uncertainty%20in%20Neural%20Networks.ipynb\n",
    "# The network structure is basically copied, while the learning code has been written mostly by me\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import importlib\n",
    "\n",
    "from training.util import GaussianMixture\n",
    "import training.bbb as bbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'training.bbb' from 'd:\\\\Uni\\\\Bachelorarbeit\\\\VariationalBayesianDL\\\\training\\\\bbb.py'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(bbb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"No cuda device available; using the CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on MNIST\n",
    "\n",
    "import training.mnist\n",
    "\n",
    "batch_size = 5\n",
    "trainloader = training.mnist.flattened_trainloader(batch_size)\n",
    "\n",
    "pi = 0.5 # 0.25, 0.5, 0.75\n",
    "sigma1 = np.exp(-1) # 0, 1, 2\n",
    "sigma2 = np.exp(-7) # 6, 7, 8\n",
    "prior = GaussianMixture(pi, sigma1, sigma2)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    bbb.BayesianLinearLayer(28*28, 400, prior, prior, device, weight_draw=\"minibatch\"), \n",
    "    nn.ReLU(), \n",
    "    bbb.BayesianLinearLayer(400, 400, prior, prior, device, weight_draw=\"minibatch\"), \n",
    "    nn.ReLU(), \n",
    "    bbb.BayesianLinearLayer(400, 10, prior, prior, device, weight_draw=\"minibatch\"), \n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.NLLLoss(reduction=\"sum\")\n",
    "for epoch in range(1):\n",
    "    loss = bbb.run_bbb_epoch(model, optimizer, loss_fn, trainloader, device)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: loss {loss / (len(trainloader) * batch_size)}\")\n",
    "print(f\"Final loss {loss / (len(trainloader) * batch_size)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9185999631881714\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    corrects = 0\n",
    "    samples = 0\n",
    "    for data, target in testloader:\n",
    "        data = torch.flatten(data, start_dim=1).to(device)\n",
    "        target = target.to(device)\n",
    "        outputs = net(data)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        corrects += ((preds - target) == 0).sum()\n",
    "        samples += len(data)\n",
    "    print(f\"Test accuracy: {corrects / samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9228999614715576\n"
     ]
    }
   ],
   "source": [
    "net2 = BayesianNetwork(prior, prior).to(device)\n",
    "net2.load_state_dict(torch.load(\"models/bbb_mnist_adam.pth\"))\n",
    "\n",
    "with torch.no_grad():\n",
    "    net2.train(False)\n",
    "    corrects = 0\n",
    "    samples = 0\n",
    "    for data, target in testloader:\n",
    "        data = torch.flatten(data, start_dim=1).to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        outputs = net2(data)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        corrects += ((preds - target) == 0).sum()\n",
    "        samples += len(data)\n",
    "    print(f\"Test accuracy: {corrects / samples}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96836cc28e460061bca45187f20cd83662f914d0b92933e0c7f2f0f17d1b293c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
